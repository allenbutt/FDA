{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FDA Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Begin by importing pandas, regular expressions, and numpy\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import json\n",
    "import datetime\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import re\n",
    "import urllib\n",
    "import time\n",
    "import os\n",
    "\n",
    "\n",
    "#If selenium is giving issue, use pip install selenium on its own line first\n",
    "#pip install webdriver-manager\n",
    "\n",
    "DOMAIN = \"https://open.fda.gov/data/downloads/\"\n",
    "URL = \"https://open.fda.gov/data/downloads/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - ====== WebDriver manager ======\n",
      "[WDM] - Current google-chrome version is 102.0.5005\n",
      "[WDM] - Get LATEST chromedriver version for 102.0.5005 google-chrome\n",
      "[WDM] - Driver [C:\\Users\\Allen\\.wdm\\drivers\\chromedriver\\win32\\102.0.5005.61\\chromedriver.exe] found in cache\n"
     ]
    }
   ],
   "source": [
    "#The FDA website does not load the doanloadable files unless you scroll to that area of the page first\n",
    "#Web-Scraping involves using the Selenium webdriver to open the site with Chrome, navigate to the\n",
    "    #needed area, and hit the correct buttons at the correct time\n",
    "\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "import selenium.common.exceptions\n",
    "from selenium import webdriver\n",
    "import time\n",
    "\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "driver.get(\"https://www.google.com\")\n",
    "\n",
    "driver.get(URL)\n",
    "driver.maximize_window()\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "button1 = driver.find_element(By.CLASS_NAME, \"button.bg-primary.clr-white\")\n",
    "button1.click()\n",
    "\n",
    "time.sleep(1)\n",
    " \n",
    "element_link=WebDriverWait(driver, 10).until(EC.presence_of_element_located(\n",
    "   (By.XPATH, '//*[@id=\"Medical Device Event\"]')))\n",
    "\n",
    "driver.execute_script(\"arguments[0].scrollIntoView(true)\", element_link)\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "button2 = driver.find_element(By.XPATH, '//*[@id=\"Medical Device Event\"]/section/button')\n",
    "button2.click()\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "html = driver.execute_script(\"return document.getElementsByTagName('html')[0].innerHTML\")\n",
    "#print (html)\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Snip HTML to just the portion in question\n",
    "pattern = \"Hide(.*?)All other data\"\n",
    "#pattern = \"Hide(.*?)download.open.fda.gov/device/event/2012q1/device-event-0002-of-0002.json.zip\"\n",
    "substring = re.search(pattern, html).group(1)\n",
    "#print(substring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Itemize links into array\n",
    "import lxml.html\n",
    "\n",
    "newlist = lxml.html.fromstring(substring)\n",
    "newlist = newlist.xpath('//a/@href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 1 started \n",
      "Download 1 completed \n",
      "File 1 extracted\n",
      "Creating Dataframe with JSON 1\n",
      "Dataframe Created\n",
      "Download 2 started \n",
      "Download 2 completed \n",
      "File 2 extracted\n",
      "Appending Dataframe with JSON 2\n",
      "JSON 2 appended\n",
      "Download 3 started \n",
      "Download 3 completed \n",
      "File 3 extracted\n",
      "Appending Dataframe with JSON 3\n",
      "JSON 3 appended\n",
      "Download 4 started \n",
      "Download 4 completed \n",
      "File 4 extracted\n",
      "Appending Dataframe with JSON 4\n",
      "JSON 4 appended\n",
      "Download 5 started \n",
      "Download 5 completed \n",
      "File 5 extracted\n",
      "Appending Dataframe with JSON 5\n",
      "JSON 5 appended\n",
      "Download 6 started \n",
      "Download 6 completed \n",
      "File 6 extracted\n",
      "Appending Dataframe with JSON 6\n",
      "JSON 6 appended\n",
      "Download 7 started \n",
      "Download 7 completed \n",
      "File 7 extracted\n",
      "Appending Dataframe with JSON 7\n",
      "JSON 7 appended\n",
      "Download 8 started \n",
      "Download 8 completed \n",
      "File 8 extracted\n",
      "Appending Dataframe with JSON 8\n",
      "JSON 8 appended\n",
      "Download 9 started \n",
      "Download 9 completed \n",
      "File 9 extracted\n",
      "Appending Dataframe with JSON 9\n",
      "JSON 9 appended\n",
      "Download 10 started \n",
      "Download 10 completed \n",
      "File 10 extracted\n",
      "Appending Dataframe with JSON 10\n",
      "JSON 10 appended\n",
      "Download 11 started \n",
      "Download 11 completed \n",
      "File 11 extracted\n",
      "Appending Dataframe with JSON 11\n",
      "JSON 11 appended\n",
      "Download 12 started \n",
      "Download 12 completed \n",
      "File 12 extracted\n",
      "Appending Dataframe with JSON 12\n",
      "JSON 12 appended\n",
      "Download 13 started \n",
      "Download 13 completed \n",
      "File 13 extracted\n",
      "Appending Dataframe with JSON 13\n",
      "JSON 13 appended\n",
      "Download 14 started \n",
      "Download 14 completed \n",
      "File 14 extracted\n",
      "Appending Dataframe with JSON 14\n",
      "JSON 14 appended\n",
      "Download 15 started \n",
      "Download 15 completed \n",
      "File 15 extracted\n",
      "Appending Dataframe with JSON 15\n",
      "JSON 15 appended\n",
      "Download 16 started \n",
      "Download 16 completed \n",
      "File 16 extracted\n",
      "Appending Dataframe with JSON 16\n",
      "JSON 16 appended\n",
      "Download 17 started \n",
      "Download 17 completed \n",
      "File 17 extracted\n",
      "Appending Dataframe with JSON 17\n",
      "JSON 17 appended\n",
      "Download 18 started \n",
      "Download 18 completed \n",
      "File 18 extracted\n",
      "Appending Dataframe with JSON 18\n",
      "JSON 18 appended\n",
      "Download 19 started \n",
      "Download 19 completed \n",
      "File 19 extracted\n",
      "Appending Dataframe with JSON 19\n",
      "JSON 19 appended\n",
      "Download 20 started \n",
      "Download 20 completed \n",
      "File 20 extracted\n",
      "Appending Dataframe with JSON 20\n",
      "JSON 20 appended\n",
      "Download 21 started \n",
      "Download 21 completed \n",
      "File 21 extracted\n",
      "Appending Dataframe with JSON 21\n",
      "JSON 21 appended\n",
      "Download 22 started \n",
      "Download 22 completed \n",
      "File 22 extracted\n",
      "Appending Dataframe with JSON 22\n",
      "JSON 22 appended\n",
      "Download 23 started \n",
      "Download 23 completed \n",
      "File 23 extracted\n",
      "Appending Dataframe with JSON 23\n",
      "JSON 23 appended\n",
      "Download 24 started \n",
      "Download 24 completed \n",
      "File 24 extracted\n",
      "Appending Dataframe with JSON 24\n",
      "JSON 24 appended\n",
      "Download 25 started \n",
      "Download 25 completed \n",
      "File 25 extracted\n",
      "Appending Dataframe with JSON 25\n",
      "JSON 25 appended\n",
      "Download 26 started \n",
      "Download 26 completed \n",
      "File 26 extracted\n",
      "Appending Dataframe with JSON 26\n",
      "JSON 26 appended\n",
      "Download 27 started \n",
      "Download 27 completed \n",
      "File 27 extracted\n",
      "Appending Dataframe with JSON 27\n",
      "JSON 27 appended\n",
      "Download 28 started \n",
      "Download 28 completed \n",
      "File 28 extracted\n",
      "Appending Dataframe with JSON 28\n",
      "JSON 28 appended\n",
      "Download 29 started \n",
      "Download 29 completed \n",
      "File 29 extracted\n",
      "Appending Dataframe with JSON 29\n",
      "JSON 29 appended\n",
      "Download 30 started \n",
      "Download 30 completed \n",
      "File 30 extracted\n",
      "Appending Dataframe with JSON 30\n",
      "JSON 30 appended\n",
      "Download 31 started \n",
      "Download 31 completed \n",
      "File 31 extracted\n",
      "Appending Dataframe with JSON 31\n",
      "JSON 31 appended\n",
      "Download 32 started \n",
      "Download 32 completed \n",
      "File 32 extracted\n",
      "Appending Dataframe with JSON 32\n",
      "JSON 32 appended\n",
      "Download 33 started \n",
      "Download 33 completed \n",
      "File 33 extracted\n",
      "Appending Dataframe with JSON 33\n",
      "JSON 33 appended\n",
      "Download 34 started \n",
      "Download 34 completed \n",
      "File 34 extracted\n",
      "Appending Dataframe with JSON 34\n",
      "JSON 34 appended\n",
      "Download 35 started \n",
      "Download 35 completed \n",
      "File 35 extracted\n",
      "Appending Dataframe with JSON 35\n",
      "JSON 35 appended\n",
      "Download 36 started \n",
      "Download 36 completed \n",
      "File 36 extracted\n",
      "Appending Dataframe with JSON 36\n",
      "JSON 36 appended\n",
      "Download 37 started \n",
      "Download 37 completed \n",
      "File 37 extracted\n",
      "Appending Dataframe with JSON 37\n",
      "JSON 37 appended\n",
      "Download 38 started \n",
      "Download 38 completed \n",
      "File 38 extracted\n",
      "Appending Dataframe with JSON 38\n",
      "JSON 38 appended\n",
      "Export file saved as 'data.csv'\n"
     ]
    }
   ],
   "source": [
    "#Follow links in array to download/process ZIPs\n",
    "\n",
    "#Specify Download Path\n",
    "path = 'C:/Users/Allen/Documents/FDA'\n",
    "#pathinverse = 'C:\\Users\\Allen\\Documents\\FDA'\n",
    "import requests, zipfile\n",
    "from io import BytesIO\n",
    "\n",
    "#Run loop, opening JSONs\n",
    "loopnumber = 0\n",
    "datamain = \"\"\n",
    "for snuh in range(172, 210):\n",
    "    print('Download ' + (str(loopnumber+1)) + \" started \")\n",
    "    url = newlist[snuh]\n",
    "    import requests, zipfile\n",
    "    req = requests.get(url)\n",
    "    print('Download ' + (str(loopnumber+1)) + \" completed \")\n",
    "    zipfile = zipfile.ZipFile(BytesIO(req.content))\n",
    "    #filename = \"FDA\" + str(snuh+1)\n",
    "    filename = \"FDAdata.json\"\n",
    "    for i, f in enumerate(zipfile.filelist):\n",
    "        f.filename = filename.format(i)\n",
    "        zipfile.extract(f)\n",
    "    print('File ' + (str(loopnumber+1)) + ' extracted')\n",
    "    data = json.load(open(r'C:\\Users\\Allen\\Documents\\FDA\\FDAdata.json'))\n",
    "    data = data[\"results\"]\n",
    "    datamain = data\n",
    "    if loopnumber == 0:\n",
    "        print('Creating Dataframe with JSON ' + (str(loopnumber+1)))\n",
    "        dfmain = pd.json_normalize(data,\n",
    "                  record_path = \"device\",\n",
    "                  meta = [\"report_number\",\"report_source_code\",\"date_received\",\"event_type\",\"type_of_report\",\"mdr_text\"],\n",
    "                  record_prefix = \"_\",\n",
    "                  errors = \"ignore\")\n",
    "        print('Dataframe Created')\n",
    "    else:\n",
    "        print('Appending Dataframe with JSON ' + (str(loopnumber+1)))\n",
    "        dfnew = pd.json_normalize(data,\n",
    "                  record_path = \"device\",\n",
    "                  meta = [\"report_number\",\"report_source_code\",\"date_received\",\"event_type\",\"type_of_report\",\"mdr_text\"],\n",
    "                  record_prefix = \"_\",\n",
    "                  errors = \"ignore\")\n",
    "        dfmain = pd.concat([dfmain, dfnew])\n",
    "        #dfmain.append(dfnew)\n",
    "        print('JSON ' + (str(loopnumber+1)) + ' appended')\n",
    "        \n",
    "    os.remove(path + \"/\" + filename)\n",
    "    loopnumber = loopnumber + 1\n",
    "\n",
    "dfmain.to_csv(r'data.csv', index = False)\n",
    "print(\"Export file saved as 'data.csv'\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Open and save the JSON file. Cull metadata, only keep results.\n",
    "data = json.load(open(r'C:\\Users\\Allen\\Documents\\FDA\\device-event-0001-of-0001.json'))\n",
    "data = data[\"results\"]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Normalize the JSON into a dataframe\n",
    "\n",
    "dfmain = pd.json_normalize(data,\n",
    "                  record_path = \"device\",\n",
    "                  meta = [\"report_number\",\"report_source_code\",\"date_received\",\"event_type\",\"type_of_report\",\"mdr_text\"],\n",
    "                  record_prefix = \"_\",\n",
    "                  errors = \"ignore\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Keep only relevant columns\n",
    "dfmain = dfmain[[\"_device_report_product_code\",\"_brand_name\",\"_generic_name\",\"_manufacturer_d_name\",\"type_of_report\",\"report_number\",\"report_source_code\",\n",
    "                 \"date_received\",\"event_type\",\"mdr_text\"]]\n",
    "\n",
    "#Rename columns\n",
    "dfmain.columns = [\"product_code\",\"brand_name\",\"generic_name\",\"manufacturer_name\",\"type_of_report\",\"report_number\",\n",
    "                        \"report_source_code\",\"date_received\",\"event_type\",\"mdr_text\"]\n",
    "\n",
    "#Update date column to date format\n",
    "dfmain[\"date_received\"] = pd.to_datetime(dfmain[\"date_received\"])\n",
    "\n",
    "#Remove brackets from type of report column\n",
    "dfmain['type_of_report'] = dfmain['type_of_report'].str.join(', ')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Rename columns\n",
    "dfmain.columns = [\"product_code\",\"brand_name\",\"generic_name\",\"manufacturer_name\",\"type_of_report\",\"report_number\",\n",
    "                        \"report_source_code\",\"date_received\",\"event_type\",\"mdr_text\"]\n",
    "\n",
    "#Update date column to date format\n",
    "dfmain[\"date_received\"] = pd.to_datetime(dfmain[\"date_received\"])\n",
    "\n",
    "#Remove brackets from type of report column\n",
    "dfmain['type_of_report'] = dfmain['type_of_report'].str.join(', ')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Input_Start_Date = datetime.date(2020, 1, 1)\n",
    "Input_End_Date = datetime.date(2020, 1, 31)\n",
    "\n",
    "Input_Start_Date"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Export to CSV\n",
    "dfmain.to_csv(r'data.csv', index = False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def get_soup(URL):\n",
    "    return bs(requests.get(URL).text, 'html.parser')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "file_link = {}\n",
    "for link in get_soup(URL).findAll(\"a\", attrs={'href': re.compile(\".zip\")}):\n",
    "    file_link = link.get('href')\n",
    "print(file_link)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open(link.text, 'wb') as file:\n",
    "    response = requests.get(DOMAIN + file_link)\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "bs(requests.get(URL).text, 'html.parser')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "button = soup.find('button', {\"clr-white weight-700 bg-primary'})\n",
    "button['data-title']\n",
    "#'Huawei Matebook X Pro 53010CBS Laptop'\n",
    "button['data-button-title']\n",
    "#'Intel i5, 256GB SSD'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "html_content = requests.get(URL).text\n",
    "soup = bs(html_content, \"lxml\")\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "html = urllib.urlopen(URL).read()\n",
    "soup = bs(html, 'html.parser')\n",
    "\n",
    "your_data = list()\n",
    "\n",
    "for line in soup.findAll('span', attrs={'id': 'target_0'}):\n",
    "    your_data.append(line.text)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "soup = bs(requests.get(URL).text, 'html.parser')\n",
    "your_data = list()\n",
    "for line in soup.findAll('span', attrs={'id': 'target_0'}):\n",
    "    your_data.append(line.text)\n",
    "\n",
    "print(your_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
